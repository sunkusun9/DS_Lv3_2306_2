{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa73290",
   "metadata": {},
   "source": [
    "## 문제 6\n",
    "\n",
    "**Kaggle 형** train_prob.csv로 문제 target을 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 target 예측하여 다음과 같은 형식의 answer6.csv를 만들어라.\n",
    "\n",
    "id, target\n",
    "\n",
    "0, 6.9\n",
    "\n",
    "5, 7.8\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "**평가지표**\n",
    "\n",
    "$RMSE(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y_i-\\hat{y_i})^2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8453bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860630d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec706fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_prob.csv', index_col='id')\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5fbe22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['targetA'] = df_train['target'] <= 7.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae14295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 {'B': 'C'} [83634, 147361, 9005]\n",
      "cat4 {'A': 'B', 'D': 'B'} [239397, 603]\n",
      "cat6 {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'} [234203, 5145, 652]\n",
      "cat7 {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'} [4606, 19784, 214027, 1583]\n",
      "cat8 {'B': 'G', 'F': 'E'} [30338, 96743, 2953, 76085, 33881]\n",
      "cat9 {'C': 'H', 'D': 'B', 'E': 'L'} [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968]\n"
     ]
    }
   ],
   "source": [
    "repl_list = [\n",
    "    ('cat3', {'B': 'C'}, [83634, 147361, 9005]),\n",
    "    ('cat4', {'A': 'B', 'D': 'B'}, [239397, 603]), \n",
    "    ('cat6', {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'}, [234203, 5145, 652]),\n",
    "    ('cat7', {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'}, [4606, 19784, 214027, 1583]),\n",
    "    ('cat8', {'B': 'G', 'F': 'E'}, [30338, 96743, 2953, 76085, 33881]),\n",
    "    ('cat9', {'C': 'H', 'D': 'B', 'E': 'L'}, [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968])\n",
    "]\n",
    "\n",
    "# 반복문을 통해 처리합니다.\n",
    "for c, d, cnt in repl_list:\n",
    "    df_train[c] = df_train[c].replace(d)\n",
    "    if (df_train[c].value_counts().sort_index() != cnt).sum() != 0:\n",
    "        print('error', c, d, cnt)\n",
    "    print(c, d, cnt)\n",
    "    df_test[c] = df_test[c].replace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b0170a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat0    {}\n",
       "cat1    {}\n",
       "cat2    {}\n",
       "cat3    {}\n",
       "cat4    {}\n",
       "cat5    {}\n",
       "cat6    {}\n",
       "cat7    {}\n",
       "cat8    {}\n",
       "cat9    {}\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.select_dtypes('object').apply(lambda x: set(x.unique()) - set(df_train[x.name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3860e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "mu_A, std_A = 6.769, 0.616\n",
    "mu_B, std_B = 8.123, 0.527\n",
    "\n",
    "df_train_sub = df_train.loc[\n",
    "    (df_train['target'] > norm.ppf(0.99, loc=mu_A, scale=std_A)) |\n",
    "    (df_train['target'] < norm.ppf(0.01, loc=mu_B, scale=std_B))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6ea7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pt', 'passthrough',\n",
       "                                                  ['cont0', 'cont1', 'cont2',\n",
       "                                                   'cont3', 'cont4', 'cont5',\n",
       "                                                   'cont6', 'cont7', 'cont8',\n",
       "                                                   'cont9', 'cont10', 'cont11',\n",
       "                                                   'cont12', 'cont13']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categori...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bytree=0.25,\n",
       "                               gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "                               max_depth=2, min_child_weight=1, missing=None,\n",
       "                               n_estimators=500, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=123,\n",
       "                               reg_alpha=0.1, reg_lambda=0.1,\n",
       "                               scale_pos_weight=1, seed=None, silent=True,\n",
       "                               subsample=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct_xgb = ColumnTransformer([\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)]),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'), ['cat{}'.format(i) for i in range(10)])\n",
    "])\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "    max_depth=2, # 트리의 최대 깊이: 2\n",
    "    reg_alpha=0.1, # L1 규제: 0.1\n",
    "    reg_lambda=0.1, # L2 규제: 0.1\n",
    "    colsample_bytree=0.25, # 트리 당 컬럼 샘플링 비율: 0.25\n",
    "    n_estimators=500, # 트리의 수: 500\n",
    "    random_state=123\n",
    ")\n",
    "clf_xgb = make_pipeline(ct_xgb, clf_xgb)\n",
    "X_xgb = ['cont{}'.format(i) for i in range(14)] + ['cat{}'.format(i) for i in range(10)]\n",
    "clf_xgb.fit(df_train_sub[X_xgb], df_train_sub['targetA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d75bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['targetA_prob'] = clf_xgb.predict_proba(df_train[X_xgb])[:, 1]\n",
    "df_test['targetA_prob'] = clf_xgb.predict_proba(df_test[X_xgb])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb8b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 4에서 뽑아낸 파생변수를 만들어봅니다.\n",
    "q = [i * 0.01 for i in range(101)]\n",
    "for i in range(0, 14):\n",
    "    col = 'cont{}'.format(i)\n",
    "    col_q = col + '_q' \n",
    "    q_val = df_train[col].quantile(q)\n",
    "    q_val.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "    q_cat = pd.cut(df_train[col], bins=q_val, right=True)\n",
    "    q_mean = df_train.groupby(q_cat)['target'].mean()\n",
    "    df_train[col_q] = q_cat.map(q_mean).astype('float')\n",
    "    df_test[col_q] = \\\n",
    "                    pd.cut(df_test[col], bins=q_val, right=True).map(q_mean).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75fff77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e2caee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.84207099, 0.84352739, 0.84673595, 0.84073641, 0.83766386]),\n",
       " 0.8421469216828141)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "ct_lr = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_lr = ['cat{}'.format(i) for i in range(10)] + ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_lr = make_pipeline(ct_lr, LinearRegression())\n",
    "scores_ = cross_val_score(reg_lr, df_train[X_lr], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_ = np.sqrt(-scores_)\n",
    "score_ = np.mean(scores_)\n",
    "scores_, score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a3191",
   "metadata": {},
   "source": [
    "## 선형모델을 사용할 때 유의 사항\n",
    "\n",
    "Unknown 범주값에 대해서 OneHotEncoder 에서 handle_unknown='ignore'로 하면,\n",
    "\n",
    "그 변수에 대해서는 모든 값이 0이 가변수를 반환합니다. (Unknown 범주값: Test 셋에서 Train에 나오지 않는 범주값을 일컫습니다.)\n",
    "\n",
    "하지만, OneHotEncoder를 handle_unknown='ignore'로 하면 drop='first'를 사용할 수 없습니다.\n",
    "\n",
    "(1.0 이후 버젼은 허용합니다. 쩝...)\n",
    "\n",
    "선형 모델을 사용하지 않으면 문제 없습니다. \n",
    "\n",
    "drop='first'를 사용하지 않으면, 가변수 간에 완전한 다중공선성을 갖게 되는데요,\n",
    "\n",
    "선형 모델의 계수(coefficient)가 큰 값을 지니게 됩니다. \n",
    "\n",
    "따라서, 불안정한 모델이 만들어지게 되고, \n",
    "\n",
    "학습에서 등장하지 않은 경우(Ex 가변수가 모두 0)에 대해서는 전혀 엉뚱한 값이 나오게 됩니다.\n",
    "\n",
    "선형 모델을 사용하고자 하고, 사용하고자 하는 변수가 그렇다면.\n",
    "\n",
    "이에 대한 대처법 test에 train에 나오지 않는 범주값이 나올 경우 대체 시켜줍니다. \n",
    "\n",
    "   Ex) 가장 많이 나온 범주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "506f4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lr.fit(df_train[X_lr], df_train['target'])\n",
    "pd.DataFrame(\n",
    "    reg_lr.predict(df_test[X_lr]),\n",
    "    columns=['target'],\n",
    "    index=df_test.index\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff69795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0388694 ,  0.03764582,  0.06233596,  0.01982507,  0.00640983,\n",
       "         0.08562987,  0.00846555,  0.05141216,  0.02535578,  0.06141578,\n",
       "         0.14500394,  0.00692817, -0.00232896, -0.02088899,  0.02644641,\n",
       "         0.01319598,  0.01820396,  0.00130193, -0.01233047,  0.04228771,\n",
       "         0.06995946,  0.03070072,  0.00263135, -0.00412637,  0.02514557,\n",
       "         0.06184112,  0.03042122,  0.0329391 ,  0.01639208,  0.22146555,\n",
       "         0.36151574,  0.56243077,  0.32152849,  0.5638488 ,  0.28192552,\n",
       "         0.45796113,  0.52076853,  0.32273993,  0.30980146,  0.2535911 ,\n",
       "         0.20738769,  0.10024969,  0.23161635, -1.13442501]),\n",
       " -27.19109449333468)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀계수가 말도 안되게 큰게 있을지고 확인해 보시면 좋습니다.\n",
    "reg_lr[1].coef_, reg_lr[1].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcfdf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8480552830027995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답셋에 대한 성능을 봅니다.\n",
    "mean_squared_error(df_ans['target'], reg_lr.predict(df_test[X_lr])) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4718485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.84199133, 0.84347491, 0.84660574, 0.84084008, 0.83760069]),\n",
       " 0.8421025512385348)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제3에서 만들었던 PCA를 적용해봅니다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "ct_lr_2 = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=3)), ['cont0', 'cont5', 'cont8', 'cont9', 'cont12']),\n",
    "    ('pt', 'passthrough', ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_lr_2 = ['cat{}'.format(i) for i in range(10)] + ['cont{}_q'.format(i) for i in range(14)]\\\n",
    "    + ['cont0', 'cont5', 'cont8', 'cont9', 'cont12', 'targetA_prob']\n",
    "reg_lr_2 = make_pipeline(ct_lr_2, LinearRegression())\n",
    "scores_ = cross_val_score(reg_lr_2, df_train[X_lr_2], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_ = np.sqrt(-scores_)\n",
    "score_ = np.mean(scores_)\n",
    "scores_, score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afa8a8",
   "metadata": {},
   "source": [
    "**Q: 범주형 변수들의 차원을 낮추는 방법이 있을까요?**\n",
    "\n",
    "**A: TruncatedSVD를 사용해 볼만 합니다.**\n",
    "\n",
    "sklearn에서 제공하는 문서를 인용합니다.\n",
    "\n",
    "**Init signature**\n",
    "\n",
    "TruncatedSVD(\n",
    "    n_components=2,\n",
    "    algorithm='randomized',\n",
    "    n_iter=5,\n",
    "    random_state=None,\n",
    "    tol=0.0,\n",
    ")\n",
    "\n",
    "**Docstring**\n",
    "\n",
    "Dimensionality reduction using truncated SVD (aka LSA).\n",
    "\n",
    "This transformer performs linear dimensionality reduction by means of\n",
    "truncated singular value decomposition (SVD). Contrary to PCA, this\n",
    "estimator does not center the data before computing the singular value\n",
    "decomposition. This means it can work with scipy.sparse matrices\n",
    "efficiently.\n",
    "\n",
    "In particular, truncated SVD works on term count/tf-idf matrices as\n",
    "returned by the vectorizers in sklearn.feature_extraction.text. In that\n",
    "context, it is known as latent semantic analysis (LSA).\n",
    "\n",
    "mean centering을 하지 않기 때문에 sparse한 셋에 대해서 효율적으로 작동합니다. \n",
    "\n",
    "Text mining 기법(LSA)에서 활용하는 방법인데요, 가변수는 sparse한 특징이 있기 때문에\n",
    "\n",
    "잘 맞을 꺼라 판단됩니다. 특히 범주의 수준이 크면 용이하리라 생각됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b9d586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.84213783, 0.84385401, 0.84688552, 0.84101823, 0.83797625]),\n",
       " 0.8423743687616456)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncated SVD로 모델을 만들어 봅니다.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "ct_lr_3 = ColumnTransformer([\n",
    "    ('ohe', make_pipeline(OneHotEncoder(drop='first'), TruncatedSVD(n_components=10)), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_lr_3 = ['cat{}'.format(i) for i in range(10)] + ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_lr_3 = make_pipeline(ct_lr_3, LinearRegression())\n",
    "scores_ = cross_val_score(reg_lr_3, df_train[X_lr_3], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_ = np.sqrt(-scores_)\n",
    "score_ = np.mean(scores_)\n",
    "scores_, score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0b8ae7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.84321514, 0.84458143, 0.84735953, 0.84161917, 0.83843339]),\n",
       " 0.8430417333299711)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost 모델 만들어 봅니다.\n",
    "# 실행시간이 깁니다. \n",
    "import xgboost as xgb\n",
    "\n",
    "ct_xgb = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_xgb = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_xgb = make_pipeline(ct_xgb, xgb.XGBRegressor(max_depth=2, n_estimators=500, colsample_bytree=0.25, random_state=123))\n",
    "scores_ = cross_val_score(reg_xgb, df_train[X_xgb], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_ = np.sqrt(-scores_)\n",
    "score_ = np.mean(scores_)\n",
    "scores_, score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25381522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.84183269, 0.84334553, 0.84639468, 0.84054509, 0.83742355]),\n",
       " 0.8419083077583673)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4개의 모델을 앙상블해봅니다.\n",
    "# 실행시간이 깁니다.\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "reg_vt = VotingRegressor([\n",
    "    ('lr', reg_lr),\n",
    "    ('lr_2', reg_lr_2),\n",
    "    ('lr_3', reg_lr_3),\n",
    "    ('xgb', reg_xgb)\n",
    "])\n",
    "X_vt = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)]\\\n",
    "    + ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "scores_ = cross_val_score(reg_vt, df_train[X_vt], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_ = np.sqrt(-scores_)\n",
    "score_ = np.mean(scores_)\n",
    "scores_, score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4c3e5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 모델을 최종제출 합니다.\n",
    "reg_vt.fit(df_train[X_vt], df_train['target'])\n",
    "pd.DataFrame(\n",
    "    reg_vt.predict(df_test[X_vt]),\n",
    "    columns=['target'],\n",
    "    index=df_test.index\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a84b652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847476481802959"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답셋에 대한 성능을 봅니다.\n",
    "mean_squared_error(df_ans['target'], reg_vt.predict(df_test[X_vt])) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab739e",
   "metadata": {},
   "source": [
    "**여러분 3일간 고생 많으셨습니다.**\n",
    "\n",
    "**더 높은 단계에서 다시 만나는 날이 오기를 기다리겠습니다.**\n",
    "\n",
    "**감사합니다.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942dc1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
