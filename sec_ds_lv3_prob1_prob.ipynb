{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75850728",
   "metadata": {},
   "source": [
    "# 시험장 환경 정보\n",
    "\n",
    "Python: 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
    "\n",
    "|모듈|버젼|\n",
    "|----|----|\n",
    "|pandas|0.25.1|\n",
    "|numpy|1.18.5|\n",
    "|sklearn|0.21.3|\n",
    "|scipy|1.5.2|\n",
    "|mlxtend|0.15.0.0|\n",
    "|statsmodels|0.11.1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b1901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a5207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 모듈 설정\n",
    "# 참고용 차트를 출력하기 위함\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719eb2d",
   "metadata": {},
   "source": [
    "# 문제 개요\n",
    "\n",
    "다음은 폴더블 폰의 힌지에 들어가는 스프링 내구력을 테스트한 실험 결과이다. \n",
    "\n",
    "스프링 측정값과 스프링에 가한 부하 정보와 함께, 테스트 통과/실패 (failure) 결과가 기재되어 있다. \n",
    "\n",
    "개발부서는 테스트 비용을 줄이기 위해 failure 여부를 맞추는 모델을 만들고자 한다.\n",
    "\n",
    "변수명은 보안을 위해 measurement_0과 같이 익명화되었다.\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "학습데이터: train_prob.csv, 21,458 rows, 25 columns\n",
    "\n",
    "테스트데이터: test_prob.csv, 5,112 rows, 24 columns, \n",
    "\n",
    "테스트정답셋: test_prob_ans.csv, 5,112 rows, 1 columns\n",
    "\n",
    "\n",
    "컬럼명\t설명\t타입\n",
    "\n",
    "|변수명|설명|타입|\n",
    "|--|--------------|------|\n",
    "|id|실험 고유 번호|정수형|\n",
    "|product_code|스프링 코드|범주형|\n",
    "|loading|스프링에 가한 부하|실수형|\n",
    "|attribute_0|구성 소재1|범주형|\n",
    "|attribute_1|구성 소재2|범주형|\n",
    "|attribute_2|구성 소재3|정수형|\n",
    "|attribute_3|구성 소재4|정수형|\n",
    "|measurement_0 ~ 17|측정값 0~17|실수형|\n",
    "|failure|성공여부|이진형(0, 1)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b80d1407",
   "metadata": {},
   "source": [
    "# 전처리(Preprocessing)\n",
    "\n",
    "train_prob.csv를 불러 온다. 이를 basetable이리고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76ca3fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18.040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.213</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.057</td>\n",
       "      <td>...</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17.295</td>\n",
       "      <td>...</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19.346</td>\n",
       "      <td>...</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n",
       "id                                                                           \n",
       "0             A    80.10  material_7  material_8            9            5   \n",
       "1             A    84.89  material_7  material_8            9            5   \n",
       "2             A    82.43  material_7  material_8            9            5   \n",
       "3             A   101.07  material_7  material_8            9            5   \n",
       "4             A   188.06  material_7  material_8            9            5   \n",
       "\n",
       "    measurement_0  measurement_1  measurement_2  measurement_3  ...  \\\n",
       "id                                                              ...   \n",
       "0               7              8              4         18.040  ...   \n",
       "1              14              3              3         18.213  ...   \n",
       "2              12              1              5         18.057  ...   \n",
       "3              13              2              6         17.295  ...   \n",
       "4               9              2              8         19.346  ...   \n",
       "\n",
       "    measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
       "id                                                                  \n",
       "0          10.672          15.859          17.594          15.193   \n",
       "1          12.448          17.947          17.915          11.755   \n",
       "2          12.715          15.607             NaN          13.798   \n",
       "3          12.471          16.346          18.377          10.020   \n",
       "4          10.337          17.082          19.932          12.428   \n",
       "\n",
       "    measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
       "id                                                                   \n",
       "0           15.029             NaN          13.034          14.684   \n",
       "1           14.732          15.425          14.395          15.631   \n",
       "2           16.711          18.631          14.094          17.946   \n",
       "3           15.250          15.562          16.154          17.172   \n",
       "4           16.182          12.760          13.153          16.412   \n",
       "\n",
       "    measurement_17  failure  \n",
       "id                           \n",
       "0          764.100        0  \n",
       "1          682.057        0  \n",
       "2          663.376        0  \n",
       "3          826.282        0  \n",
       "4          579.885        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basetable = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_basetable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b4c4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21458 entries, 0 to 26569\n",
      "Data columns (total 25 columns):\n",
      "product_code      21458 non-null object\n",
      "loading           21257 non-null float64\n",
      "attribute_0       21458 non-null object\n",
      "attribute_1       21458 non-null object\n",
      "attribute_2       21458 non-null int64\n",
      "attribute_3       21458 non-null int64\n",
      "measurement_0     21458 non-null int64\n",
      "measurement_1     21458 non-null int64\n",
      "measurement_2     21458 non-null int64\n",
      "measurement_3     21146 non-null float64\n",
      "measurement_4     21016 non-null float64\n",
      "measurement_5     20893 non-null float64\n",
      "measurement_6     20818 non-null float64\n",
      "measurement_7     20692 non-null float64\n",
      "measurement_8     20605 non-null float64\n",
      "measurement_9     20469 non-null float64\n",
      "measurement_10    20399 non-null float64\n",
      "measurement_11    20278 non-null float64\n",
      "measurement_12    20171 non-null float64\n",
      "measurement_13    20063 non-null float64\n",
      "measurement_14    19976 non-null float64\n",
      "measurement_15    19855 non-null float64\n",
      "measurement_16    19750 non-null float64\n",
      "measurement_17    19640 non-null float64\n",
      "failure           21458 non-null int64\n",
      "dtypes: float64(16), int64(6), object(3)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_basetable.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f35976",
   "metadata": {},
   "source": [
    "# 단계 1\n",
    "\n",
    "basetable에 measurement_3 ~17 각각의 행이 결측인지 나타내는 파생 변수를 만든다. \n",
    "\n",
    "파생 변수는 이진 형식이고, False는 미결측 True는 결측을 의미한다. \n",
    "\n",
    "파생 변수의 이름은 measurement 번호에 따라 isna_3 ~ 17로 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d8bd808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isna_3     0\n",
       "isna_4     0\n",
       "isna_5     0\n",
       "isna_6     0\n",
       "isna_7     0\n",
       "isna_8     0\n",
       "isna_9     0\n",
       "isna_10    0\n",
       "isna_11    0\n",
       "isna_12    0\n",
       "isna_13    0\n",
       "isna_14    0\n",
       "isna_15    0\n",
       "isna_16    0\n",
       "isna_17    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basetable[['isna_{}'.format(i) for i in range(3, 18)]] = \\\n",
    "    df_basetable[['measurement_{}'.format(i) for i in range(3, 18)]].isna()\n",
    "# 결측치의 수를 확인합니다.\n",
    "df_basetable[['isna_{}'.format(i) for i in range(3, 18)]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173737d",
   "metadata": {},
   "source": [
    "## 단계 2\n",
    "\n",
    "이 과제를 맡은 데이터분석가 지희는 measurement_3~17의 결측치 처리 방안을 고민하던 중, \n",
    "\n",
    "개발부서에서 measurement_17은 product_code별로 failure를 예측하기 위해 \n",
    "\n",
    "measurement_3 ~ measurement_9을 다음과 같이 선형 조합하여 생성한 값이라는 정보를 받았다. \n",
    "\n",
    "$measurement_{17}=\\beta_{3}measurement_{3}+\\beta_{4}measurement_{4}+...+\\beta_{9}measurement_{9}+\\beta_{0}$\n",
    "\n",
    "이는 즉,\n",
    "\n",
    "$measurement_{3}=\\beta'_{4}measurement_{4}+\\beta'_{5}measurement_{5}+...+\\beta'_{17}measurement_{17}+\\beta'_{0}$\n",
    "\n",
    "...\n",
    "\n",
    "$measurement_{9}=\\beta''_{3}measurement_{3}+\\beta''_{4}measurement_{4}+...+\\beta''_{17}measurement_{17}+\\beta''_{0}$\n",
    "\n",
    "와 같이 measurement_3 ~ measurement_9의 각 변수들도 나머지 변수들과 선형 관계를 지닌다. \n",
    "\n",
    "이 점을 이용하여 대상 변수를 번갈아 가면서 예측 모델을 만들어 최대한 원래 값에 가깝게 복원할 수 있다. \n",
    "\n",
    "이러한 반복적인 결측치 복원 방법을 사내 데이터분석 연구소에 문의 했더니 다음과 같은 가이드를 주었다. \n",
    "\n",
    "> sklearn 모듈에 아직은 실험 단계이지만, 비슷한 경우에 문제 없이 사용했던 사례가 있어 의견을 드립니다. \n",
    "\n",
    "> from sklearn.experimental import enable_iterative_imputer 구문을 사용하여 실험 단계인 모듈을 활성화하고, \n",
    "\n",
    "> sklearn.impute.IterativeImputer를 사용한다면 원하는 결과를 얻을 수 있습니다.\n",
    "\n",
    "가이드의 내용을 참조하여 basetable의 measurement_3~9와 measurement_17 결측치를 복원하라.\n",
    "\n",
    "\n",
    "입력 변수] measurement_3 ~ 9, measurement_17 (입력 변수 순서에 유의)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.experimental.enable_iterative_imputer\n",
    "\n",
    "sklearn.impute.IterativeImputer, random_state=123\n",
    "\n",
    "sklearn.linear_model.LinearRegression\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a94de17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement_3',\n",
       " 'measurement_4',\n",
       " 'measurement_5',\n",
       " 'measurement_6',\n",
       " 'measurement_7',\n",
       " 'measurement_8',\n",
       " 'measurement_9',\n",
       " 'measurement_17']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IterativeImputer를 활성화합니다.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# IterativeImputer 설정입니다.\n",
    "imp = IterativeImputer(\n",
    "    estimator=LinearRegression(),\n",
    "    random_state=123\n",
    ")\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "X_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1ca555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measurement_3     0\n",
       "measurement_4     0\n",
       "measurement_5     0\n",
       "measurement_6     0\n",
       "measurement_7     0\n",
       "measurement_8     0\n",
       "measurement_9     0\n",
       "measurement_17    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법1: GroupBy를 통한 방법입니다.\n",
    "# fit_transform 후에 numpy array(shape: 데이터수 x 컬럼수) 가 넘어옵니다.\n",
    "# apply 후에 결합을 할 수 있도록, 인덱스와 컬럼을 내용에 맞추어 셋팅을 하여 반환시켜줍니다.\n",
    "df_basetable[X_imp] = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x[X_imp]), index=x.index, columns=X_imp) \n",
    ")\n",
    "df_basetable[X_imp].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b87b5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법2: 반복문을 통한 방법입니다.\n",
    "# loc[boolean index][컬럼리스트]로하면 얕은 복사(Shallow Copy) 후, 데이터 변경을 하는 것입니다.\n",
    "# 이럴 경우 Reference Warning이 발생합니다(내용 예상하지 못하는 결과를 초례할 수 있다.)\n",
    "# 이를 방지하기 위해\n",
    "# loc[boolean index, 컬럼 리스트] filter한 데이터프레임에 해당 컬럼을 바로 수정하도록 합니다.\n",
    "for i in df_basetable['product_code'].unique():\n",
    "    s_idx = df_basetable['product_code'] == i\n",
    "    df_basetable.loc[s_idx, X_imp] = imp.fit_transform(df_basetable.loc[s_idx, X_imp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "880e5cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement_3',\n",
       " 'measurement_4',\n",
       " 'measurement_5',\n",
       " 'measurement_6',\n",
       " 'measurement_7',\n",
       " 'measurement_8',\n",
       " 'measurement_9',\n",
       " 'measurement_17']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b095b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_code\n",
       "A    0.999982\n",
       "B    0.999983\n",
       "C    0.999986\n",
       "E    0.999990\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고 코드: 범주형 타입(여기서는 product_code)에 따라 모델을 만들고, \n",
    "# 그에 따라 모델을 적용하여 결과를 도출합니다.\n",
    "# product_code 별로 measurement_3~9를 입력으로, \n",
    "# measurement_17을 예측하는 LinearRegression 모델을 만들고 \n",
    "# product_code에 따라 그에 대응하는 모델로 예측하여, r2를 측정하는 루틴을,\n",
    "# GroupBy를 이용하여 만들어 봅니다.\n",
    "from sklearn.metrics import r2_score\n",
    "# product_code에 따라 모델을 만듭니다.\n",
    "# 아래 명령의 수행 결과는 product_code가 인덱스고 내용이 LinearRegression인 Series가 만들어 집니다.\n",
    "# 주의: 모델을 재활용해서는 안 되고, 아래처럼 모델을 만들 때마다 생성을 해주어야 합니다.\n",
    "s_lr = df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: LinearRegression().fit(x.iloc[:, :-1], x.iloc[:, -1])\n",
    ")\n",
    "# product_code마다 r2를 측정합니다.\n",
    "# apply에 넘어오는 DataFrame에 name 어트리뷰트에는 DataFrame의 product_code 값이 넘어옵니다.\n",
    "# 이를 이용하여 위에서 생성한 모델을 참조하고 예측합니다.\n",
    "df_basetable.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: r2_score(x.iloc[:, -1], s_lr.loc[x.name].predict(x.iloc[:, :-1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95edba8",
   "metadata": {},
   "source": [
    "## 단계 3\n",
    "\n",
    "measurement_10~16까지의 결측치는 모두 product_code별 평균으로 대치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bea1389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measurement_10    0\n",
       "measurement_11    0\n",
       "measurement_12    0\n",
       "measurement_13    0\n",
       "measurement_14    0\n",
       "measurement_15    0\n",
       "measurement_16    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cols = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_basetable[mean_cols] = \\\n",
    "        df_basetable.groupby('product_code')[mean_cols].transform(lambda x: x.fillna(x.mean()))\n",
    "df_basetable[mean_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62884d7",
   "metadata": {},
   "source": [
    "Hint] 전처리 단계에서 보간 결과를 확인해 보기 위한 각 변수의 평균과 표본표준편차.\n",
    "\n",
    "| |3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|\n",
    "|-|-|-|-|-|-|-|-|--|--|--|--|--|--|--|--|\n",
    "|mean|17.796|11.736|17.131|17.506|11.719|19.022|11.434|16.034|19.194|11.734|15.666|16.033|15.051|16.398|701.768|\n",
    "|std|0.997|0.994|0.994|0.992|0.993|1.005|0.997|1.278|1.579|1.433|1.149|1.461|1.478|1.671|119.180|\n",
    "\n",
    "열의 이름의 숫자는 measurement_ 번호, 값은 소수점 3째 자리까지 반올림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ff22f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>17.796</td>\n",
       "      <td>11.736</td>\n",
       "      <td>17.131</td>\n",
       "      <td>17.506</td>\n",
       "      <td>11.719</td>\n",
       "      <td>19.022</td>\n",
       "      <td>11.434</td>\n",
       "      <td>16.034</td>\n",
       "      <td>19.194</td>\n",
       "      <td>11.734</td>\n",
       "      <td>15.666</td>\n",
       "      <td>16.033</td>\n",
       "      <td>15.051</td>\n",
       "      <td>16.398</td>\n",
       "      <td>701.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.278</td>\n",
       "      <td>1.579</td>\n",
       "      <td>1.433</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.478</td>\n",
       "      <td>1.671</td>\n",
       "      <td>119.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           3       4       5       6       7       8       9      10      11  \\\n",
       "mean  17.796  11.736  17.131  17.506  11.719  19.022  11.434  16.034  19.194   \n",
       "std    0.997   0.994   0.994   0.992   0.993   1.005   0.997   1.278   1.579   \n",
       "\n",
       "          12      13      14      15      16       17  \n",
       "mean  11.734  15.666  16.033  15.051  16.398  701.768  \n",
       "std    1.433   1.149   1.461   1.478   1.671  119.180  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인을 합니다.\n",
    "df_basetable[['measurement_{}'.format(i) for i in range(3, 18)]].agg(['mean', 'std'])\\\n",
    "        .rename(columns=lambda x: x.split('_')[1]).applymap(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218dab47",
   "metadata": {},
   "source": [
    "# 문제1 ~ 10:00\n",
    "\n",
    "(basetable을 사용) measurement_3~16까지 결측 여부가 failure에 영향이 있는지를 파악하고, \n",
    "\n",
    "failure를 분류하는 데 도움이 될 만한 것은 예측 모델의 입력 변수로 사용하고자 한다. \n",
    "\n",
    "이를 위해 전처리 과정에서 뽑아낸 isna_3~16을 활용한다.\n",
    "\n",
    "n이 3부터 16까지, 즉 measurement_3~16까지 다음의 검정을 수행한다. \n",
    "\n",
    "$H_0: P(failure=True|measurement_{n}=Missing)=P(failure=True)$\n",
    "\n",
    "$H_1: P(failure=True|measurement_{n}=Missing) \\neq P(failure=True)$\n",
    "\n",
    "모집단의 $P(failure=True) = 0.2114$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed64b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91304a06",
   "metadata": {},
   "source": [
    "## 단계 1-1\n",
    "\n",
    "우선, measurement_3으로 위 검정을 시행해보자.\n",
    "\n",
    "$H_0: P(failure=True|isna_{3}=True)=0.2114$\n",
    "\n",
    "$H_1: P(failure=True|isna_{3}=True) \\neq 0.2114$\n",
    "\n",
    "으로 바꿀 수 있다.\n",
    "\n",
    "$P(failure=True|isna_{3}=True)$은 표본수가 충분하여 중심극한정리에 의해 정규분포를 따르는 것은 분석가 간에 이견이 없다고 한다. \n",
    "\n",
    "위 검정의 p-value를 구하여 보고 힌트에 주어진 p-value와 비교하여 검정 방법에 문제가 없음을 확인하라.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n",
    "\n",
    " Hint] p-value는 0.0037(소수점 다섯째 자리에서 반올림하여 넷째 자리까지 표시)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b98c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c87c44",
   "metadata": {},
   "source": [
    "## 단계 1-2\n",
    "\n",
    "measuremenet_3을 포함하여 measurement_4 ~ 16까지 위 검정을 반복하고 \n",
    "\n",
    "귀무가설을 기각할 수 있는 경우의 p-value의 합을 A라고 한다. (유의 수준은 5%로 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49aa12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df03a86a",
   "metadata": {},
   "source": [
    "## 단계 1-3\n",
    "\n",
    "검정 결과 귀무가설을 기각할 수 있는 경우는 총 두 건이다. \n",
    "\n",
    "해당 파생 변수명의 뒷 자리 번호 순으로 na_1, na_2로 파생 변수를 만들어 prob1 데이터셋을 생성하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e8c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33bbf8c",
   "metadata": {},
   "source": [
    "A의 값을 소수점 넷째 자리에서 반올림하여 셋째 자리까지 출력하시오. \n",
    "\n",
    "Ex) 0.052"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d2d0f",
   "metadata": {},
   "source": [
    "# 문제 2\n",
    "\n",
    "첫째는 스프링 개발 업체들은 실험이 제품 별로 공정하게 진행이 됐는지를 의문을 가지고 있다.\n",
    "\n",
    "product_code에 따라 개발 업체가 다르다. \n",
    "\n",
    "product_code에 대해서 스프링에 가한 부하(loading)를 동일하게 했는지 조사하라.\n",
    "\n",
    "둘째는, attribute_0와 attribute_1은 스프링을 구성하는 주요 소재이다. \n",
    "\n",
    "failure와는 관계가 없음이 이전에 검증되었다. \n",
    "\n",
    "하지만, 이에 대한 재확인 요청을 받아 attribute_0와 attribute_1은 failure와 상관없음을 확인한다.\n",
    "\n",
    "이를 위해 다음 단계를 수행하라.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb314a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfc21275",
   "metadata": {},
   "source": [
    "## 단계 2-1\n",
    "\n",
    "prob1에서 입력 변수 loading에 결측이 없는 행들을 뽑아 prob2 데이터프레임을 만든다.\n",
    "\n",
    "Hint] prob2의 데이터 수는 21,257 이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef461d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ebf527",
   "metadata": {},
   "source": [
    "## 단계 2-2\n",
    "\n",
    "prob2에 loading의 각 행들에 자연 로그 함수를 적용하여 파생 변수 loading_log를 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0152db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2245b2",
   "metadata": {},
   "source": [
    "## 단계 2-3\n",
    "\n",
    "loading_log가 product_code 각각에 대해서 정규성을 지니고 있는지 확인하고자 한다.\n",
    "\n",
    "이를 위해 Jarque-Bera로 검정하고 결과의 p-value가 0.05가 넘는 product_code의 수를 B라고 하자.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd8734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce7e5cf",
   "metadata": {},
   "source": [
    "## 단계 2-4\n",
    "\n",
    "loading_log 변수를 product_code로 구분했을 때, \n",
    "\n",
    "등분산성을 보이는지 Bartlett 검정을 통해 확인한다.\n",
    "\n",
    "검정 결과에서 p-value를 C라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 에서 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d8245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b058c6b2",
   "metadata": {},
   "source": [
    "## 단계 2-5\n",
    "\n",
    "product_code에 대한 분산분석(ANOVA)을 통해서 loading_log 평균에 차이가 있는지 검정한다.\n",
    "\n",
    "그 결과 중 p-value를 D라고 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats 제공 기능 활용\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47f9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c23d2c",
   "metadata": {},
   "source": [
    "## 단계 2-6\n",
    "\n",
    "Chi-square 검정을 통해 attribute_0, attribute_1의 결합값이 failure와 연관이 있는지 조사하라. \n",
    "\n",
    "attribute_0, attribute_1의 결합값의 의미 attribute_0=material_7, attribute_1=material_8 이라면, 이 둘의 결합값은\n",
    "matertial_7material_8를 의미한다.\n",
    "\n",
    "(유의 수준 1%) 연관이 있다면 E값은 1 없으면 0으로 한다.\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " scipy.stats.chi2_contingency, correction=False\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3530be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af42805f",
   "metadata": {},
   "source": [
    "B + C + D + E의 값을 소수점 셋째 자리에서 반올림하여 둘째 자리까지 출력하시오.\n",
    "\n",
    "Ex) 3.16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe1afc",
   "metadata": {},
   "source": [
    "# 문제 3\n",
    "\n",
    "로지스틱 회귀모델로 수치형 변수 measurement_0 ~ 17, \n",
    "\n",
    "loading과 이진형인 na_1, na_2 중에서 최적의 성능을 보이는 입력 변수들을 찾고자 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a63c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ec19e2",
   "metadata": {},
   "source": [
    "## 단계 3-1\n",
    "\n",
    "prob1을 복사하여 prob3을 만든다. loading의 결측치는 loading의 평균으로 대치한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e376a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61eb5594",
   "metadata": {},
   "source": [
    "## 단계 3-2: \n",
    "    \n",
    "prob3를 80%는 학습데이터 prob3_train으로 20%는 테스트데이터 prob3_test로 나눈다. \n",
    "\n",
    "prob3_train의 failure가 1인 비율과 prob3_test의 failure가 1의 비율을 동일하게 한다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.model_selection.train_test_split, random_state=123, \n",
    " \n",
    " train과 test의 failure의 비율은 stratify 매개 변수를 이용하여 맞춘다.\n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac987b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7716c3a",
   "metadata": {},
   "source": [
    "## 단계 3-3\n",
    "\n",
    "prob3_train의 수치형 입력 변수 loading, measurement_0 ~ 17을 표준화한다. \n",
    "\n",
    "prob3_train의 표준화 설정으로 prob3_test의 loading, measurement_0 ~ 17에도 적용한다. \n",
    "\n",
    "표준화 처리한 prob3_train과 prob3_test는 문제 4와 문제 5에서 사용한다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.preprocessing 제공 기능 활용, \n",
    " \n",
    " 문제 지시사항 외 Default 값 사용\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17f958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b20b6ef8",
   "metadata": {},
   "source": [
    "## 단계 3-4\n",
    "    \n",
    "로지스틱 회귀모델을 사용하여 loading, measurement_0~17과 na_1, na_2를 입력 변수로 하여 prob3_train을 학습한다. \n",
    "\n",
    "로지스틱 회귀모델을 prob3_test로 성능을 측정한 값을 A라고 한다.\n",
    "\n",
    "입력 변수: loading, measurement_0~17, na_1, na_2\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "\n",
    "**함수 가이드**\n",
    "\n",
    " sklearn.linear_model.LogisticRegression, solver='lbfgs', 문제 지시사항 외 Default 값 사용\n",
    " \n",
    " sklearn.metrics.roc_auc_score\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86e3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cba372a",
   "metadata": {},
   "source": [
    "## 단계 3-5\n",
    "\n",
    "loading, measurement_0 ~ 17, na_1, na_2를 후보 입력 변수로 한다. \n",
    "\n",
    "전진 선택법을 사용하여 이 후보 입력 변수 중에서 최적의 성능을 보이는 입력 변수의 조합을 찾는다. \n",
    "\n",
    "전진 선택법의 선택 기준은 prob3_train을 대상으로 5겹 층화교차검증(5-Fold stratified cross validation)을 하고 \n",
    "\n",
    "겹외(OOF, Out-Of Fold) 성능의 평균값으로 한다. 전진 선택 과정에서 선택했던 변수를 제외하지 않는다. \n",
    "\n",
    "입력 변수: 본 단계 요건 참고\n",
    "\n",
    "대상 변수: failure \n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "mlxtend.feature_selection.SequentialFeatureSelector\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver='lbfgs'\n",
    "\n",
    "sklearn.metrics.roc_auc_score\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold, random_state=123, shuffle=True\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713233f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e7c6893",
   "metadata": {},
   "source": [
    "## 단계 3-6\n",
    "\n",
    "단계 3-5에서 찾은 최적의 입력 변수 조합으로 로지스틱 회귀모델을 사용하여 prob3_train을 학습하고 \n",
    "\n",
    "prob3_test로 성능을 측정한 값을 B라고 한다.\n",
    "\n",
    "입력 변수: **단계 3-5**에서 도출한 최적의 입력 변수 조합\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수 가이드**\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver='lbfgs'\n",
    "\n",
    "sklearn.metrics.roc_auc_score\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96e152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac40eec",
   "metadata": {},
   "source": [
    "A-B값을 소수점 넷째 자리에서 반올림하여 셋째 자리까지 출력하시오\n",
    "\n",
    "Ex) 1.135"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed67461",
   "metadata": {},
   "source": [
    "# 문제 4\n",
    "\n",
    "차원 축소 기법을 통한 데이터의 특성과 failure 분류 성능을 높힐 만한 요소를 살펴 본다. \n",
    "\n",
    "첫째로, loading을 제외하고, measurement_0 ~ 17을 입력으로 failure를 대상 변수로 Linear Discrimant Analysis(LDA) 모델을 만든다. \n",
    "\n",
    "범주가 두 개인 failure를 분류한다는 점에서 LDA 모델은 measurement_0 ~ 17를 한 개의 경계점으로 \n",
    "\n",
    "failure를 최대한 정확하게 구분하도록 하나의 연속형 변수로 변환한다. \n",
    "\n",
    "실험 대상의 내구력을 나타낸다고 할 수 있는 LDA 변환값과 \n",
    "\n",
    "실험에서 스프링에 가한 부하(loading)와 상관도를 측정하여, \n",
    "\n",
    "스프링에 따라 부하(loading)를 조정한 정도를 살펴본다.\n",
    "\n",
    "둘째로, PCA를 사용하여 차원 감소로 failure 분류 성능에 얼마나 효과가 있을지 살펴본다.\n",
    "\n",
    "문제3에서 사용했던, 전처리(loading 결측치 처리와 표준화 과정을 거친) 과정을 거친 prob3_train과 prob3_test를 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee8e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3579a749",
   "metadata": {},
   "source": [
    "## 단계 4-1\n",
    "\n",
    "prob3_train에서 measurement_0 ~ 17을 입력으로 failure를 대상 변수로 하여 LDA(Linear Discriminant Analysis) 모델을 학습한다. \n",
    "\n",
    "measurement_0 ~ 17에 대한 LDA의 변환값과 loading과 스피어만 상관도 (spearman correlation)의 p-value를 구하여 A라고 한다.\n",
    "\n",
    "입력 변수] measurement_0 ~ 17 (순서에 유의 하시오)\n",
    "\n",
    "대상 변수] failure\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.discriminant_analysis 제공 기능 활용\n",
    "\n",
    "scipy.stats.spearmanr\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbc9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e726a4a",
   "metadata": {},
   "source": [
    "## 단계 4-2\n",
    "\n",
    "prob3_train에서 measurement_0 ~ 17을 대상으로 주성분분석(Principal Component Analysis, PCA) 모델을 학습한다. \n",
    "\n",
    "분산 설명율이 높은 순으로 주성분을 변수명을 pca_0 ~ 17하여 prob3_train에 추가하여 prob4_train을 만든다. \n",
    "\n",
    "prob3_test에 prob3_train를 학습했던 PCA 모델로 동일한 방법으로 pca0 ~17 파생 변수를 추가하여 prob4_test를 만든다.\n",
    "\n",
    "입력 변수] measurement_0 ~ 17 (순서에 유의 하시오)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.decomposition.PCA, random_state=123\n",
    "\n",
    "문제 지시사항 외 Default 값 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11d71204",
   "metadata": {},
   "source": [
    "## 단계 4-3\n",
    "\n",
    "초기에 loading을 입력 변수로 하여 prob4_train을 학습하고, prob4_test에 대한 성능을 측정한다.\n",
    "\n",
    "여기에 pca_0에서 pca_17까지 입력 변수를 하나씩 추가 하면서, \n",
    "\n",
    "즉 분산 설명율이 높은 순으로 컴포넌트를 하나씩 추가하여 prob4_train를 학습하고 prob4_test의 성능을 측정 했을 때, \n",
    "\n",
    "최적의 성능을 보인 컴포넌트들의 분산 설명율의 합을 B라고 한다. (만일 없다면 B = 0이다.)\n",
    "\n",
    "입력 변수: 설명 참고\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC(area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.linear_model.LogisticRegression, solver=’lbfgs’\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19ae14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7a7e38",
   "metadata": {},
   "source": [
    "A + B를 소수점 셋째 자리에서 반올림하여 둘째 자리까지 구하라.\n",
    "\n",
    "Ex) 12.34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba3524",
   "metadata": {},
   "source": [
    "# 문제 5\n",
    "\n",
    "랜덤포레스트 분류기(Random-Forest Classifier)의 최적의 하이퍼 파라미터(Hyper-Parameter, 초매개변수)를 탐색하고자 한다.\n",
    "\n",
    "문제3에서 사용했던, 전처리(loading 결측치 처리와 표준화 과정을 거친) 과정을 거친 prob3_train과 prob3_test를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e99809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05189b7d",
   "metadata": {},
   "source": [
    "## 단계 5-1\n",
    "\n",
    "sklearn에서 제공하는 랜덤포레스트 분류기(Random-Forest Classifier)의 하이퍼 파라미터 중 \n",
    "\n",
    "n_estimators, max_depth 그리고 min_samples_split의 최적 조합을 탐색한다. \n",
    "\n",
    "탐색 값은 아래에 제공한 하이퍼 파라미터의 모든 조합이다. \n",
    "\n",
    "prob3_train을 대상으로 5-겹 층화교차검증(5-fold stratified cross validation)으로 \n",
    "\n",
    "각각 층의 겹외셋(OOF set, Out-Of-Fold set)의 성능에 대한 평균을 기준으로 하이퍼 파라미터를 선택한다.\n",
    "\n",
    "  - n_estimators: [5, 10, 15]\n",
    "\n",
    "  - max_depth: [5, 6, 7]\n",
    "  \n",
    "  - min_samples_split: [256, 512]\n",
    "\n",
    "Hint] 모든 하이퍼 파라미터의 조합의 수는 18개이다\n",
    "\n",
    "입력 변수: loading, measurement_0 ~ 17, na_1, na_2 (순서에 유의)\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC (area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.ensemble.RandomForestClassifier, random_state=123 \n",
    "\n",
    "itertools.product 필요시 사용\n",
    "\n",
    "sklearn.model_selection.cross_val_score 필요시 사용\n",
    "\n",
    "sklearn.model_selection.StratifiedKFold, random_state=123, shuffle=True\n",
    "\n",
    "sklearn.model_selection.GridSearchCV 필요시 사용\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226741f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eacc40ad",
   "metadata": {},
   "source": [
    "## 단계 5-2\n",
    "\n",
    "단계 5-1에서 구한 최적 하이퍼 파라미터로 설정한 랜덤포레스트 분류기(Random-Forest Classifier)를 사용하여 prob3_train 학습하고, \n",
    "\n",
    "prob3_test로 성능을 측정하여 이 값을 A라고 한다.\n",
    "\n",
    "입력 변수: loading, measurement_0 ~ 17, na_1, na_2 (순서에 유의)\n",
    "\n",
    "대상 변수: failure\n",
    "\n",
    "성능 지표: AUC (area under of ROC curve)\n",
    "\n",
    "---\n",
    "**함수가이드**\n",
    "\n",
    "sklearn.ensemble.RandomForestClassifier, random_state=123 \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebecc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "044dd522",
   "metadata": {},
   "source": [
    "A값을 소수점 넷째 자리에서 반올림하여 3째 자리까지 출력하시오.\n",
    "\n",
    "Ex) 0.123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933ca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
